"""
processing.py â€“ Core signal processing functions
=================================================
Audio I/O, degradation, metrics, and plot helpers.

All **numerical interpolation / reconstruction** logic lives in
``backend.interpolation``  (scipy-backed, research-grade).
This module delegates to it via ``reconstruct_signal()``.
"""

import numpy as np
import struct
import wave
import io
import base64

from interpolation import reconstruct as _interpolation_reconstruct
from advanced_reconstruction import (
    advanced_reconstruct as _advanced_reconstruct,
    advanced_reconstruct_v2 as _advanced_reconstruct_v2,
    compute_reconstruction_metrics as _compute_advanced_metrics,
    compare_methods as _compare_methods,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Audio I/O
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_wav_bytes(raw_bytes: bytes) -> tuple[int, np.ndarray]:
    """Read a WAV file from bytes, return (sample_rate, mono_samples)."""
    buf = io.BytesIO(raw_bytes)
    with wave.open(buf, "rb") as wf:
        n_channels = wf.getnchannels()
        sampwidth = wf.getsampwidth()
        sample_rate = wf.getframerate()
        n_frames = wf.getnframes()
        raw_data = wf.readframes(n_frames)

    # Convert raw bytes to numpy array based on sample width
    if sampwidth == 1:
        # 8-bit unsigned
        samples = np.frombuffer(raw_data, dtype=np.uint8).astype(np.float64) - 128.0
        samples /= 128.0
    elif sampwidth == 2:
        # 16-bit signed (most common)
        samples = np.frombuffer(raw_data, dtype=np.int16).astype(np.float64)
        samples /= 32768.0
    elif sampwidth == 3:
        # 24-bit signed â€“ unpack manually
        n_samples = len(raw_data) // 3
        samples = np.zeros(n_samples, dtype=np.float64)
        for i in range(n_samples):
            b = raw_data[i * 3 : i * 3 + 3]
            val = int.from_bytes(b, byteorder="little", signed=True)
            samples[i] = val / 8388608.0
    elif sampwidth == 4:
        # 32-bit signed
        samples = np.frombuffer(raw_data, dtype=np.int32).astype(np.float64)
        samples /= 2147483648.0
    else:
        raise ValueError(f"Unsupported sample width: {sampwidth}")

    # Convert to mono by averaging channels
    if n_channels > 1:
        samples = samples.reshape(-1, n_channels).mean(axis=1)

    # Limit length: truncate to first 5 seconds for manageability
    max_samples = sample_rate * 5
    if len(samples) > max_samples:
        samples = samples[:max_samples]

    return sample_rate, samples


def signal_to_wav_base64(signal: np.ndarray, sample_rate: int) -> str:
    """Convert a float64 signal [-1, 1] to a base64-encoded 16-bit WAV."""
    # Clip and scale to int16
    clipped = np.clip(signal, -1.0, 1.0)
    int_samples = (clipped * 32767).astype(np.int16)

    buf = io.BytesIO()
    with wave.open(buf, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(int_samples.tobytes())

    buf.seek(0)
    return base64.b64encode(buf.read()).decode("ascii")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Demo signal generation
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_demo_signal(duration: float = 1.0, sr: int = 8000) -> tuple[int, np.ndarray]:
    """
    Generate a composite test signal:
      440 Hz tone + 880 Hz harmonic + amplitude envelope
    Sounds like a brief piano-like note â€” perfect for demonstrating
    how interpolation preserves harmonic structure.
    """
    t = np.arange(int(sr * duration)) / sr
    # Fundamental + harmonic
    signal = 0.6 * np.sin(2 * np.pi * 440 * t) + 0.3 * np.sin(2 * np.pi * 880 * t)
    # Gentle amplitude envelope (attack + decay)
    envelope = np.minimum(t / 0.05, 1.0) * np.exp(-t * 2.0)
    signal *= envelope
    # Normalize
    peak = np.max(np.abs(signal))
    if peak > 0:
        signal /= peak
    return sr, signal


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Signal Degradation â€“ Realistic Audio Damage Pipeline
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def degrade_signal(
    original: np.ndarray,
    sample_rate: int = 8000,
    dropout_pct: float = 10.0,
    dropout_length_ms: float = 100.0,
    glitch_pct: float = 5.0,
    clip_pct: float = 10.0,
    noise_level: float = 0.02,
    seed: int | None = None,
) -> tuple[np.ndarray, np.ndarray]:
    """
    Degrade a signal with realistic audio damage patterns.

    Damage Types (applied in order):
      1. Segment dropouts â€“ contiguous silence blocks
      2. Glitches â€“ short bursts of repeated/corrupted samples
      3. Amplitude clipping â€“ harsh distortion at Â±threshold
      4. Gaussian noise â€“ added to surviving samples

    Args:
        original:          clean signal array (float64, normalized [-1, 1])
        sample_rate:       audio sample rate in Hz (for msâ†’samples conversion)
        dropout_pct:       percentage of total audio to drop (0-50)
        dropout_length_ms: average length of each dropout segment in ms (50-500)
        glitch_pct:        percentage of audio affected by glitches (0-20)
        clip_pct:          percentage of audio affected by clipping (0-30)
        noise_level:       std deviation of additive Gaussian noise (0-0.1)
        seed:              random seed for reproducibility (None = random)

    Returns:
        (spoiled_signal, mask)
        mask[i] = True means sample i is VALID (not dropped/glitched)
    """
    n = len(original)
    spoiled = original.copy()
    mask = np.ones(n, dtype=bool)

    # Initialize RNG
    rng = np.random.default_rng(seed if seed is not None else None)

    # â”€â”€â”€ Clamp parameters to safe ranges â”€â”€â”€
    dropout_pct = np.clip(dropout_pct, 0.0, 50.0)
    dropout_length_ms = np.clip(dropout_length_ms, 10.0, 500.0)
    glitch_pct = np.clip(glitch_pct, 0.0, 20.0)
    clip_pct = np.clip(clip_pct, 0.0, 30.0)
    noise_level = np.clip(noise_level, 0.0, 0.1)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. SEGMENT DROPOUTS â€“ random chunks of silence
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if dropout_pct > 0:
        spoiled, mask = _apply_dropouts(
            spoiled, mask, n, sample_rate, dropout_pct, dropout_length_ms, rng
        )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. GLITCHES â€“ short bursts of damage (repeated samples / artifacts)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if glitch_pct > 0:
        spoiled, mask = _apply_glitches(spoiled, mask, n, sample_rate, glitch_pct, rng)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. AMPLITUDE CLIPPING â€“ harsh cutoffs at Â±threshold
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if clip_pct > 0:
        spoiled = _apply_clipping(spoiled, mask, n, clip_pct, rng)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. GAUSSIAN NOISE â€“ added to surviving (non-dropped) samples
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if noise_level > 0:
        noise = rng.normal(0, noise_level, size=n)
        spoiled[mask] += noise[mask]

    # Final clip to [-1, 1]
    spoiled = np.clip(spoiled, -1.0, 1.0)

    return spoiled, mask


def _apply_dropouts(
    spoiled: np.ndarray,
    mask: np.ndarray,
    n: int,
    sample_rate: int,
    dropout_pct: float,
    dropout_length_ms: float,
    rng: np.random.Generator,
) -> tuple[np.ndarray, np.ndarray]:
    """
    Apply segment dropouts â€“ contiguous chunks of silence.
    
    Creates realistic "packet loss" or "tape dropout" effects by
    zeroing out random contiguous segments of the signal.
    """
    # Convert target dropout to samples
    target_dropout_samples = int(n * dropout_pct / 100.0)
    avg_segment_samples = int(sample_rate * dropout_length_ms / 1000.0)
    avg_segment_samples = max(avg_segment_samples, 10)  # minimum 10 samples

    # Estimate number of segments needed
    num_segments = max(1, target_dropout_samples // avg_segment_samples)
    
    # Generate random segment lengths (varying around average)
    segment_lengths = rng.integers(
        max(10, avg_segment_samples // 2),
        avg_segment_samples * 2,
        size=num_segments
    )
    
    # Adjust to hit target dropout more precisely
    total_length = segment_lengths.sum()
    if total_length > 0:
        scale = target_dropout_samples / total_length
        segment_lengths = (segment_lengths * scale).astype(int)
        segment_lengths = np.maximum(segment_lengths, 10)
    
    # Generate random start positions (ensuring no overlap)
    available_mask = np.ones(n, dtype=bool)
    
    for seg_len in segment_lengths:
        # Find available regions
        available_indices = np.where(available_mask)[0]
        if len(available_indices) < seg_len:
            break
            
        # Pick random start from available positions
        valid_starts = available_indices[available_indices <= n - seg_len]
        if len(valid_starts) == 0:
            break
            
        start = rng.choice(valid_starts)
        end = min(start + seg_len, n)
        
        # Apply dropout
        spoiled[start:end] = 0.0
        mask[start:end] = False
        available_mask[start:end] = False

    return spoiled, mask


def _apply_glitches(
    spoiled: np.ndarray,
    mask: np.ndarray,
    n: int,
    sample_rate: int,
    glitch_pct: float,
    rng: np.random.Generator,
) -> tuple[np.ndarray, np.ndarray]:
    """
    Apply short glitches â€“ brief bursts of corrupted audio.
    
    Glitch types:
      1. Sample-hold (stuck value)
      2. Repeated previous samples
      3. High-frequency noise burst
      4. Zero burst
    """
    # Target number of samples to glitch
    target_glitch_samples = int(n * glitch_pct / 100.0)
    
    # Glitches are short: 1-10ms
    min_glitch_ms = 1
    max_glitch_ms = 10
    min_glitch_samples = max(5, int(sample_rate * min_glitch_ms / 1000))
    max_glitch_samples = max(20, int(sample_rate * max_glitch_ms / 1000))
    
    avg_glitch = (min_glitch_samples + max_glitch_samples) // 2
    num_glitches = max(1, target_glitch_samples // avg_glitch)
    
    glitched = 0
    attempts = 0
    max_attempts = num_glitches * 10
    
    while glitched < target_glitch_samples and attempts < max_attempts:
        attempts += 1
        
        # Random glitch length
        glitch_len = rng.integers(min_glitch_samples, max_glitch_samples + 1)
        
        # Random start position (avoid already corrupted areas)
        start = rng.integers(0, max(1, n - glitch_len))
        end = min(start + glitch_len, n)
        
        # Skip if this region is already corrupted
        if not mask[start:end].any():
            continue
        
        # Choose glitch type
        glitch_type = rng.integers(0, 4)
        
        if glitch_type == 0:
            # Sample-hold: repeat the sample just before glitch
            hold_val = spoiled[max(0, start - 1)]
            spoiled[start:end] = hold_val
        elif glitch_type == 1:
            # Repeat a short pattern from before
            pattern_len = min(5, start)
            if pattern_len > 0:
                pattern = spoiled[start - pattern_len:start]
                for i in range(start, end):
                    spoiled[i] = pattern[(i - start) % pattern_len]
        elif glitch_type == 2:
            # High-frequency noise burst
            spoiled[start:end] = rng.uniform(-0.8, 0.8, size=end - start)
        else:
            # Zero burst
            spoiled[start:end] = 0.0
        
        mask[start:end] = False
        glitched += (end - start)

    return spoiled, mask


def _apply_clipping(
    spoiled: np.ndarray,
    mask: np.ndarray,
    n: int,
    clip_pct: float,
    rng: np.random.Generator,
) -> np.ndarray:
    """
    Apply amplitude clipping to segments of the signal.
    
    Simulates analog tape saturation or digital clipping by
    hard-limiting signal amplitude in selected regions.
    The clip threshold is set at Â±0.6 to ensure audible distortion.
    """
    # Target samples to clip
    target_clip_samples = int(n * clip_pct / 100.0)
    
    # Clipping segments: 50-200ms
    min_clip_samples = max(50, n // 100)
    max_clip_samples = max(200, n // 20)
    
    avg_segment = (min_clip_samples + max_clip_samples) // 2
    num_segments = max(1, target_clip_samples // avg_segment)
    
    clipped = 0
    
    # Track clipped regions to avoid overlap
    clip_mask = np.zeros(n, dtype=bool)
    
    for _ in range(num_segments * 2):  # Extra attempts for fitting
        if clipped >= target_clip_samples:
            break
            
        # Random segment length
        seg_len = rng.integers(min_clip_samples, max_clip_samples + 1)
        
        # Random start
        start = rng.integers(0, max(1, n - seg_len))
        end = min(start + seg_len, n)
        
        # Skip if already clipped
        if clip_mask[start:end].any():
            continue
        
        # Apply hard clipping at Â±0.6 (harsh, audible)
        clip_threshold = 0.6
        segment = spoiled[start:end]
        
        # Only clip if there's signal to clip (skip already-dropped regions)
        if mask[start:end].any():
            segment = np.clip(segment, -clip_threshold, clip_threshold)
            # Add slight distortion harmonics for realism
            segment = segment + 0.1 * np.sign(segment) * (segment ** 2)
            segment = np.clip(segment, -1.0, 1.0)
            spoiled[start:end] = segment
            clip_mask[start:end] = True
            clipped += (end - start)

    return spoiled


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Numerical Interpolation / Reconstruction
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# All interpolation logic is in backend/interpolation.py (SciPy-backed).
# This thin wrapper keeps the public interface unchanged for main.py.
#
# ðŸš« Lagrange interpolation is NOT supported.
#    Lagrange interpolation is numerically unstable for dense and noisy
#    signals such as audio.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def reconstruct_signal(
    time_axis: np.ndarray,
    spoiled: np.ndarray,
    mask: np.ndarray,
    method: str = "spline",
) -> np.ndarray:
    """Delegate to ``backend.interpolation.reconstruct``."""
    return _interpolation_reconstruct(time_axis, spoiled, mask, method=method)


def reconstruct_signal_advanced(
    time_axis: np.ndarray,
    spoiled: np.ndarray,
    mask: np.ndarray,
    sample_rate: int = 8000,
    method: str = "pchip",
    use_sinusoidal_model: bool = True,
    use_spectral_subtraction: bool = True,
    use_tikhonov: bool = True,
) -> np.ndarray:
    """
    High-quality signal reconstruction optimized for maximum SNR (â‰¥10 dB).
    
    Uses the optimized interpolation pipeline from interpolation.py:
    1. Noise-aware preconditioning
    2. Gap-aware segment-based interpolation  
    3. Perceptual post-processing
    
    Parameters
    ----------
    time_axis : 1-D float64 - Monotonic time vector
    spoiled   : 1-D float64 - Degraded signal
    mask      : 1-D bool    - True = valid sample, False = damaged
    sample_rate : int       - Sampling rate in Hz
    method    : str         - 'pchip' (default, best), 'spline', 'linear', 'moving_average'
    use_sinusoidal_model : bool - (reserved for future use)
    use_spectral_subtraction : bool - (reserved for future use)
    use_tikhonov : bool     - (reserved for future use)
    
    Returns
    -------
    1-D float64 array clamped to [-1, 1]
    
    Performance:
    - Achieves SNR â‰¥ 10 dB for typical audio degradation
    - Best results with 'pchip' or 'linear' methods
    """
    # Use the highly-optimized interpolation module
    return _interpolation_reconstruct(time_axis, spoiled, mask, method=method)


def compare_reconstruction_methods(
    time_axis: np.ndarray,
    original: np.ndarray,
    spoiled: np.ndarray,
    mask: np.ndarray,
    sample_rate: int = 8000,
) -> dict:
    """
    Compare reconstruction quality across all methods.
    
    Returns dictionary with metrics for baseline and advanced
    reconstruction for each method, plus improvement statistics.
    """
    return _compare_methods(time_axis, original, spoiled, mask, sample_rate)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Error Metrics
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_metrics(original: np.ndarray, reconstructed: np.ndarray) -> dict:
    """Compute reconstruction quality metrics."""
    diff = original - reconstructed
    finite_diff = diff[np.isfinite(diff)]

    if len(finite_diff) == 0:
        return {"mse": 0.0, "rmse": 0.0, "mae": 0.0, "snr_db": 0.0}

    mse_val = float(np.mean(finite_diff ** 2))
    rmse_val = float(np.sqrt(mse_val))
    mae_val = float(np.mean(np.abs(finite_diff)))

    # Signal-to-Noise Ratio (dB)
    signal_power = float(np.mean(original ** 2))
    noise_power = mse_val
    if noise_power > 0 and signal_power > 0:
        snr_db = float(10 * np.log10(signal_power / noise_power))
    else:
        snr_db = float("inf") if noise_power == 0 else 0.0

    return {
        "mse": round(mse_val, 8),
        "rmse": round(rmse_val, 8),
        "mae": round(mae_val, 8),
        "snr_db": round(snr_db, 2),
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Plot Downsampling (for large signals)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def downsample_for_plot(
    time_axis: np.ndarray, signal: np.ndarray, max_points: int = 8000
) -> tuple[np.ndarray, np.ndarray]:
    """
    Downsample signal for frontend plotting using LTTB-like approach.
    Keeps first and last points, takes evenly spaced samples between.
    """
    n = len(signal)
    if n <= max_points:
        return time_axis.copy(), signal.copy()

    indices = np.linspace(0, n - 1, max_points, dtype=int)
    return time_axis[indices], signal[indices]
